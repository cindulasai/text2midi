# -*- coding: utf-8 -*-
"""
MidiGen v2.0 - AI-Powered MIDI Generator
Dynamic track generation and multi-turn conversation support.
"""

import gradio as gr
import mido
from dataclasses import dataclass, field
from typing import List, Optional, Dict, Any
import random
import re
from pathlib import Path
from datetime import datetime
import os
import json
import uuid

# Groq integration
try:
    from groq import Groq
    GROQ_AVAILABLE = True
except ImportError:
    GROQ_AVAILABLE = False
    print("Warning: Groq not installed. Using simple keyword-based parsing.")

GROQ_API_KEY = os.environ.get("GROQ_API_KEY", "")


# ============== DATA STRUCTURES ==============

@dataclass
class Note:
    """Represents a MIDI note."""
    pitch: int
    start_time: float
    duration: float
    velocity: int = 80
    channel: int = 0

@dataclass
class TrackConfig:
    """Configuration for a single track."""
    track_type: str  # lead, counter_melody, harmony, bass, drums, arpeggio, pad, fx
    instrument: str
    role: str
    priority: int = 1
    channel: int = 0

@dataclass
class Track:
    """Represents a MIDI track with notes."""
    name: str
    notes: List[Note]
    midi_program: int
    channel: int = 0
    track_type: str = "melody"

@dataclass
class GenerationSnapshot:
    """Snapshot of a generation for history."""
    timestamp: datetime
    prompt: str
    tracks: List[Track]
    tempo: int
    key: str
    mode: str
    bars: int

@dataclass
class CompositionSession:
    """Session state for multi-turn composition."""
    session_id: str = field(default_factory=lambda: str(uuid.uuid4())[:8])
    created_at: datetime = field(default_factory=datetime.now)
    
    # Current composition state
    tracks: List[Track] = field(default_factory=list)
    tempo: int = 120
    key: str = "C"
    mode: str = "major"
    genre: str = "pop"
    total_bars: int = 0
    
    # Conversation context
    messages: List[Dict[str, str]] = field(default_factory=list)
    generations: List[GenerationSnapshot] = field(default_factory=list)
    preferences: Dict[str, Any] = field(default_factory=dict)


# ============== MUSIC THEORY ==============

SCALES = {
    "major": [0, 2, 4, 5, 7, 9, 11],
    "minor": [0, 2, 3, 5, 7, 8, 10],
    "dorian": [0, 2, 3, 5, 7, 9, 10],
    "mixolydian": [0, 2, 4, 5, 7, 9, 10],
    "pentatonic_major": [0, 2, 4, 7, 9],
    "pentatonic_minor": [0, 3, 5, 7, 10],
    "blues": [0, 3, 5, 6, 7, 10],
    "harmonic_minor": [0, 2, 3, 5, 7, 8, 11],
}

NOTE_TO_MIDI = {
    "C": 60, "C#": 61, "Db": 61,
    "D": 62, "D#": 63, "Eb": 63,
    "E": 64, "F": 65, "F#": 66, "Gb": 66,
    "G": 67, "G#": 68, "Ab": 68,
    "A": 69, "A#": 70, "Bb": 70, "B": 71,
}

DRUM_MAP = {
    "kick": 36, "bass_drum": 35, "snare": 38,
    "closed_hihat": 42, "open_hihat": 46,
    "crash": 49, "ride": 51,
    "tom_low": 45, "tom_mid": 47, "tom_high": 50,
    "clap": 39, "rimshot": 37, "shaker": 70,
}

GM_INSTRUMENTS = {
    "piano": 0, "bright_piano": 1, "electric_grand": 2,
    "electric_piano": 4, "rhodes": 4, "harpsichord": 6,
    "clavinet": 7, "celesta": 8, "glockenspiel": 9,
    "music_box": 10, "vibraphone": 11, "marimba": 12,
    "xylophone": 13, "tubular_bells": 14,
    "organ": 19, "church_organ": 19, "rock_organ": 18,
    "guitar": 24, "acoustic_guitar": 25, "electric_guitar": 27,
    "clean_guitar": 27, "distortion_guitar": 30,
    "bass": 32, "electric_bass": 33, "finger_bass": 33,
    "pick_bass": 34, "fretless_bass": 35, "slap_bass": 36,
    "synth_bass": 38, "synth_bass_2": 39,
    "violin": 40, "viola": 41, "cello": 42, "contrabass": 43,
    "strings": 48, "synth_strings": 50, "slow_strings": 49,
    "choir": 52, "voice_oohs": 53, "synth_voice": 54,
    "trumpet": 56, "trombone": 57, "tuba": 58, "brass": 61,
    "saxophone": 64, "alto_sax": 65, "tenor_sax": 66,
    "clarinet": 71, "oboe": 68, "bassoon": 70,
    "flute": 73, "recorder": 74, "pan_flute": 75,
    "synth_lead": 80, "square_lead": 80, "sawtooth": 81,
    "synth_pad": 88, "warm_pad": 89, "polysynth": 90,
    "space_voice": 91, "bowed_pad": 92, "metallic_pad": 93,
    "halo_pad": 94, "sweep_pad": 95,
    "fx_rain": 96, "fx_soundtrack": 97, "fx_crystal": 98,
    "fx_atmosphere": 99, "fx_brightness": 100,
    "sitar": 104, "banjo": 105, "shamisen": 106, "koto": 107,
    "kalimba": 108, "bagpipe": 109, "fiddle": 110,
}

GENRE_CONFIG = {
    "pop": {"tempo_range": (100, 130), "key": "C", "mode": "major", "energy": "medium", "typical_tracks": 4},
    "rock": {"tempo_range": (110, 140), "key": "E", "mode": "minor", "energy": "high", "typical_tracks": 5},
    "electronic": {"tempo_range": (120, 135), "key": "A", "mode": "minor", "energy": "high", "typical_tracks": 6},
    "lofi": {"tempo_range": (70, 90), "key": "D", "mode": "minor", "energy": "low", "typical_tracks": 4},
    "jazz": {"tempo_range": (80, 140), "key": "F", "mode": "dorian", "energy": "medium", "typical_tracks": 5},
    "classical": {"tempo_range": (60, 120), "key": "G", "mode": "major", "energy": "medium", "typical_tracks": 4},
    "ambient": {"tempo_range": (60, 80), "key": "C", "mode": "major", "energy": "low", "typical_tracks": 3},
    "cinematic": {"tempo_range": (70, 100), "key": "D", "mode": "minor", "energy": "high", "typical_tracks": 7},
    "funk": {"tempo_range": (95, 115), "key": "E", "mode": "mixolydian", "energy": "high", "typical_tracks": 5},
    "rnb": {"tempo_range": (70, 100), "key": "Ab", "mode": "minor", "energy": "medium", "typical_tracks": 5},
}

CHORD_PROGRESSIONS = {
    "pop": [[0, 4, 7], [5, 9, 12], [7, 11, 14], [5, 9, 12]],
    "rock": [[0, 4, 7], [7, 11, 14], [5, 9, 12], [0, 4, 7]],
    "jazz": [[0, 4, 7, 11], [5, 9, 12, 16], [2, 5, 9, 12], [7, 11, 14, 17]],
    "lofi": [[0, 4, 7, 11], [2, 5, 9], [5, 9, 12], [7, 11, 14]],
    "electronic": [[0, 4, 7], [0, 4, 7], [5, 9, 12], [7, 11, 14]],
    "classical": [[0, 4, 7], [5, 9, 12], [4, 7, 11], [0, 4, 7]],
    "ambient": [[0, 4, 7, 11], [0, 4, 7, 11], [5, 9, 12, 16], [5, 9, 12, 16]],
    "cinematic": [[0, 3, 7], [5, 8, 12], [7, 10, 14], [3, 7, 10]],
    "funk": [[0, 4, 7, 10], [5, 9, 12], [0, 4, 7, 10], [7, 11, 14]],
    "rnb": [[0, 4, 7, 11], [2, 5, 9, 12], [5, 9, 12, 16], [7, 11, 14, 17]],
}


# ============== MIDI GENERATOR ==============

class MIDIGenerator:
    """Handles MIDI file creation."""

    def __init__(self, ticks_per_beat: int = 480):
        self.ticks_per_beat = ticks_per_beat

    def create_midi(self, tracks: List[Track], tempo: int = 120) -> mido.MidiFile:
        """Create a MIDI file from tracks."""
        midi = mido.MidiFile(ticks_per_beat=self.ticks_per_beat)
        tempo_track = mido.MidiTrack()
        midi.tracks.append(tempo_track)
        tempo_track.append(mido.MetaMessage('set_tempo', tempo=mido.bpm2tempo(tempo)))

        for track in tracks:
            midi_track = mido.MidiTrack()
            midi.tracks.append(midi_track)
            midi_track.append(mido.MetaMessage('track_name', name=track.name))

            if track.channel != 9:
                midi_track.append(mido.Message('program_change',
                                               channel=track.channel,
                                               program=track.midi_program))

            sorted_notes = sorted(track.notes, key=lambda n: n.start_time)
            events = []
            for note in sorted_notes:
                start_tick = int(note.start_time * self.ticks_per_beat)
                duration_tick = int(note.duration * self.ticks_per_beat)
                events.append((start_tick, 'note_on', note.pitch, note.velocity, track.channel))
                events.append((start_tick + duration_tick, 'note_off', note.pitch, 0, track.channel))

            events.sort(key=lambda x: (x[0], x[1] == 'note_on'))

            current_tick = 0
            for tick, msg_type, pitch, velocity, channel in events:
                delta = tick - current_tick
                midi_track.append(mido.Message(msg_type, note=pitch, velocity=velocity,
                                               channel=channel, time=delta))
                current_tick = tick

        return midi

    def merge_midi(self, existing_tracks: List[Track], new_tracks: List[Track], 
                   offset_bars: int, tempo: int) -> List[Track]:
        """Merge new tracks into existing, with time offset."""
        offset_beats = offset_bars * 4
        
        merged = list(existing_tracks)
        for new_track in new_tracks:
            # Offset all notes
            offset_notes = []
            for note in new_track.notes:
                offset_notes.append(Note(
                    pitch=note.pitch,
                    start_time=note.start_time + offset_beats,
                    duration=note.duration,
                    velocity=note.velocity,
                    channel=note.channel
                ))
            
            # Check if track type already exists
            existing = next((t for t in merged if t.track_type == new_track.track_type), None)
            if existing:
                existing.notes.extend(offset_notes)
            else:
                merged.append(Track(
                    name=new_track.name,
                    notes=offset_notes,
                    midi_program=new_track.midi_program,
                    channel=new_track.channel,
                    track_type=new_track.track_type
                ))
        
        return merged


# ============== MUSIC GENERATOR ==============

class MusicGenerator:
    """Generates musical content for different track types."""

    def generate_melody(self, root: int, mode: str, bars: int, energy: str, genre: str) -> List[Note]:
        """Generate a lead melody."""
        notes = []
        scale = SCALES.get(mode, SCALES["major"])
        beats = bars * 4
        density = {"low": 0.3, "medium": 0.5, "high": 0.7}.get(energy, 0.5)

        beat = 0.0
        while beat < beats:
            if random.random() < density:
                octave = random.choice([0, 0, 12, 12, -12])
                scale_degree = random.choice(scale)
                pitch = root + scale_degree + octave
                durations = [0.5, 1.0, 1.5, 2.0] if energy == "low" else [0.25, 0.5, 0.75, 1.0]
                duration = random.choice(durations)
                velocity = random.randint(60, 90) if energy == "low" else random.randint(70, 110)
                notes.append(Note(pitch=pitch, start_time=beat, duration=duration, velocity=velocity))
                beat += duration
            else:
                beat += 0.5
        return notes

    def generate_counter_melody(self, root: int, mode: str, bars: int, energy: str) -> List[Note]:
        """Generate a counter-melody that complements the main melody."""
        notes = []
        scale = SCALES.get(mode, SCALES["major"])
        beats = bars * 4
        
        beat = 0.0
        while beat < beats:
            if random.random() < 0.4:  # Sparser than main melody
                # Use different scale degrees for contrast
                scale_degree = random.choice(scale[2:5])  # 3rd, 4th, 5th
                pitch = root + scale_degree + random.choice([-12, 0])
                duration = random.choice([1.0, 1.5, 2.0])
                velocity = random.randint(55, 75)
                notes.append(Note(pitch=pitch, start_time=beat, duration=duration, velocity=velocity, channel=1))
                beat += duration
            else:
                beat += 1.0
        return notes

    def generate_chords(self, root: int, genre: str, bars: int) -> List[Note]:
        """Generate chord progression."""
        notes = []
        progression = CHORD_PROGRESSIONS.get(genre, CHORD_PROGRESSIONS["pop"])
        beats_per_chord = 4
        total_beats = bars * 4

        beat = 0.0
        chord_idx = 0
        while beat < total_beats:
            chord = progression[chord_idx % len(progression)]
            for interval in chord:
                pitch = root + interval - 12
                notes.append(Note(pitch=pitch, start_time=beat, duration=beats_per_chord - 0.5,
                                  velocity=70, channel=1))
            beat += beats_per_chord
            chord_idx += 1
        return notes

    def generate_arpeggio(self, root: int, genre: str, bars: int, energy: str) -> List[Note]:
        """Generate arpeggiated pattern."""
        notes = []
        progression = CHORD_PROGRESSIONS.get(genre, CHORD_PROGRESSIONS["pop"])
        beats_per_chord = 4
        total_beats = bars * 4
        
        # Arp speed based on energy
        arp_speed = {"low": 1.0, "medium": 0.5, "high": 0.25}.get(energy, 0.5)

        beat = 0.0
        chord_idx = 0
        while beat < total_beats:
            chord = progression[chord_idx % len(progression)]
            chord_beat = beat
            
            while chord_beat < beat + beats_per_chord:
                for i, interval in enumerate(chord):
                    if chord_beat + i * arp_speed < beat + beats_per_chord:
                        pitch = root + interval
                        notes.append(Note(
                            pitch=pitch, 
                            start_time=chord_beat + i * arp_speed,
                            duration=arp_speed * 0.8,
                            velocity=random.randint(60, 80),
                            channel=2
                        ))
                chord_beat += len(chord) * arp_speed
            
            beat += beats_per_chord
            chord_idx += 1
        return notes

    def generate_bass(self, root: int, genre: str, bars: int, energy: str = "medium") -> List[Note]:
        """Generate bass line."""
        notes = []
        progression = CHORD_PROGRESSIONS.get(genre, CHORD_PROGRESSIONS["pop"])
        beats_per_chord = 4
        total_beats = bars * 4

        beat = 0.0
        chord_idx = 0
        while beat < total_beats:
            chord = progression[chord_idx % len(progression)]
            bass_note = root + chord[0] - 24

            if genre in ["electronic", "rock", "funk"]:
                for i in range(8):
                    vel = 95 if i % 2 == 0 else 75
                    notes.append(Note(pitch=bass_note, start_time=beat + i * 0.5,
                                      duration=0.4, velocity=vel, channel=2))
            elif genre == "jazz":
                for i in range(4):
                    walk_note = bass_note + random.choice([0, 2, 4, 7])
                    notes.append(Note(pitch=walk_note, start_time=beat + i,
                                      duration=0.9, velocity=75, channel=2))
            else:
                for i in range(4):
                    notes.append(Note(pitch=bass_note, start_time=beat + i,
                                      duration=0.9, velocity=80, channel=2))

            beat += beats_per_chord
            chord_idx += 1
        return notes

    def generate_pad(self, root: int, mode: str, bars: int) -> List[Note]:
        """Generate sustained pad/atmosphere."""
        notes = []
        scale = SCALES.get(mode, SCALES["major"])
        total_beats = bars * 4
        
        beat = 0.0
        while beat < total_beats:
            # Long sustained chords
            duration = random.choice([4.0, 8.0])
            
            # Build a simple triad from scale
            for degree in [0, 2, 4]:
                if degree < len(scale):
                    pitch = root + scale[degree] - 12
                    notes.append(Note(
                        pitch=pitch,
                        start_time=beat,
                        duration=duration - 0.5,
                        velocity=random.randint(40, 60),
                        channel=3
                    ))
            
            beat += duration
        return notes

    def generate_drums(self, genre: str, bars: int, energy: str) -> List[Note]:
        """Generate drum pattern."""
        notes = []
        total_beats = bars * 4

        # Genre-specific patterns
        if genre == "electronic":
            kick_pattern = [0, 1, 2, 3]
            snare_pattern = [1, 3]
            hihat_pattern = [i * 0.25 for i in range(16)]
        elif genre == "jazz":
            kick_pattern = [0, 2.5]
            snare_pattern = []
            hihat_pattern = [i * (1/3) for i in range(12)]  # Swing
        elif genre == "rock":
            kick_pattern = [0, 2]
            snare_pattern = [1, 3]
            hihat_pattern = [0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5]
        else:
            kick_pattern = [0, 2]
            snare_pattern = [1, 3]
            hihat_pattern = [0, 0.5, 1, 1.5, 2, 2.5, 3, 3.5] if energy != "low" else [0, 1, 2, 3]

        for bar in range(bars):
            bar_start = bar * 4

            for beat in kick_pattern:
                notes.append(Note(pitch=DRUM_MAP["kick"], start_time=bar_start + beat,
                                  duration=0.5, velocity=100, channel=9))

            for beat in snare_pattern:
                notes.append(Note(pitch=DRUM_MAP["snare"], start_time=bar_start + beat,
                                  duration=0.5, velocity=90, channel=9))

            for beat in hihat_pattern:
                if bar_start + beat < (bar + 1) * 4:
                    vel = 60 if beat % 1 != 0 else 75
                    notes.append(Note(pitch=DRUM_MAP["closed_hihat"], start_time=bar_start + beat,
                                      duration=0.25, velocity=vel, channel=9))

            if bar % 4 == 0:
                notes.append(Note(pitch=DRUM_MAP["crash"], start_time=bar_start,
                                  duration=2.0, velocity=85, channel=9))

        return notes

    def generate_fx(self, root: int, bars: int) -> List[Note]:
        """Generate ambient FX/texture notes."""
        notes = []
        total_beats = bars * 4
        
        beat = 0.0
        while beat < total_beats:
            if random.random() < 0.15:  # Sparse
                pitch = root + random.choice([0, 7, 12, 19, 24])
                duration = random.choice([2.0, 4.0, 8.0])
                notes.append(Note(
                    pitch=pitch,
                    start_time=beat,
                    duration=duration,
                    velocity=random.randint(30, 50),
                    channel=4
                ))
            beat += random.choice([2.0, 4.0])
        return notes


# ============== TRACK PLANNER ==============

class TrackPlanner:
    """AI-powered track planning based on user prompt."""

    def __init__(self):
        self.client = None
        if GROQ_AVAILABLE and GROQ_API_KEY:
            try:
                self.client = Groq(api_key=GROQ_API_KEY)
            except:
                pass

    def plan_tracks(self, user_prompt: str, genre: str) -> List[TrackConfig]:
        """Determine track configuration based on prompt."""
        if self.client:
            return self._plan_with_ai(user_prompt, genre)
        return self._plan_with_rules(user_prompt, genre)

    def _plan_with_ai(self, user_prompt: str, genre: str) -> List[TrackConfig]:
        """Use AI to plan tracks."""
        system_prompt = """Analyze this music request and determine the optimal track configuration.
Return ONLY valid JSON (no markdown, no explanation):
{
  "total_tracks": <1-8>,
  "tracks": [
    {"type": "<lead|counter_melody|harmony|bass|drums|arpeggio|pad|fx>", "instrument": "<instrument>", "role": "<purpose>", "priority": <1-8>}
  ]
}

Rules:
- Solo instrument requests = 1-2 tracks
- Simple requests = 2-3 tracks
- Standard arrangements = 4-5 tracks
- Rich/orchestral/epic = 6-8 tracks
- NEVER exceed 8 tracks
- Match instruments to genre conventions
- Types: lead (melody), counter_melody, harmony (chords), bass, drums, arpeggio, pad, fx"""

        try:
            response = self.client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": f"Genre: {genre}\nRequest: {user_prompt}"}
                ],
                temperature=0.3,
                max_tokens=500
            )

            result_text = response.choices[0].message.content.strip()
            if "```" in result_text:
                result_text = result_text.split("```")[1].replace("json", "").strip()
            
            data = json.loads(result_text)
            
            tracks = []
            for i, t in enumerate(data.get("tracks", [])[:8]):
                tracks.append(TrackConfig(
                    track_type=t.get("type", "lead"),
                    instrument=t.get("instrument", "piano"),
                    role=t.get("role", ""),
                    priority=t.get("priority", i + 1),
                    channel=i if t.get("type") != "drums" else 9
                ))
            return tracks if tracks else self._plan_with_rules(user_prompt, genre)
            
        except Exception as e:
            print(f"AI track planning failed: {e}")
            return self._plan_with_rules(user_prompt, genre)

    def _plan_with_rules(self, user_prompt: str, genre: str) -> List[TrackConfig]:
        """Rule-based track planning fallback."""
        prompt_lower = user_prompt.lower()
        tracks = []
        
        # Detect complexity indicators
        is_simple = any(w in prompt_lower for w in ["solo", "simple", "minimal", "just", "only"])
        is_rich = any(w in prompt_lower for w in ["epic", "orchestral", "full", "rich", "complex", "cinematic"])
        
        # Detect specific instruments
        has_piano = "piano" in prompt_lower
        has_guitar = "guitar" in prompt_lower
        has_strings = "string" in prompt_lower
        has_synth = "synth" in prompt_lower
        
        if is_simple:
            # 1-2 tracks
            instrument = "piano"
            if has_guitar: instrument = "guitar"
            elif has_strings: instrument = "strings"
            elif has_synth: instrument = "synth_lead"
            
            tracks.append(TrackConfig("lead", instrument, "Main melody", 1, 0))
            if not any(w in prompt_lower for w in ["solo", "just", "only"]):
                tracks.append(TrackConfig("harmony", "electric_piano", "Light harmony", 2, 1))
        
        elif is_rich:
            # 6-8 tracks
            tracks = [
                TrackConfig("lead", "strings", "Main melody", 1, 0),
                TrackConfig("counter_melody", "flute", "Counter line", 2, 1),
                TrackConfig("harmony", "synth_pad", "Harmonic bed", 3, 2),
                TrackConfig("pad", "choir", "Atmosphere", 4, 3),
                TrackConfig("bass", "synth_bass", "Low end", 5, 4),
                TrackConfig("drums", "drums", "Rhythm", 6, 9),
                TrackConfig("arpeggio", "piano", "Movement", 7, 5),
            ]
            if random.random() > 0.5:
                tracks.append(TrackConfig("fx", "fx_atmosphere", "Texture", 8, 6))
        
        else:
            # Standard 4-5 tracks based on genre
            config = GENRE_CONFIG.get(genre, GENRE_CONFIG["pop"])
            
            tracks.append(TrackConfig("lead", "piano", "Main melody", 1, 0))
            tracks.append(TrackConfig("harmony", "electric_piano", "Chords", 2, 1))
            tracks.append(TrackConfig("bass", "bass", "Bass line", 3, 2))
            
            if genre not in ["ambient", "classical"] or "drum" in prompt_lower:
                tracks.append(TrackConfig("drums", "drums", "Rhythm", 4, 9))
            
            if genre in ["electronic", "lofi"]:
                tracks.append(TrackConfig("arpeggio", "synth_lead", "Arpeggio", 5, 3))
            elif genre in ["ambient", "cinematic"]:
                tracks.append(TrackConfig("pad", "synth_pad", "Atmosphere", 5, 3))

        return tracks


# ============== INTENT PARSER ==============

class IntentParser:
    """Parse natural language into music parameters."""

    def __init__(self):
        self.client = None
        if GROQ_AVAILABLE and GROQ_API_KEY:
            try:
                self.client = Groq(api_key=GROQ_API_KEY)
            except:
                pass
        self.track_planner = TrackPlanner()

    def parse(self, user_input: str, session: Optional[CompositionSession] = None) -> Dict[str, Any]:
        """Parse user input with session context."""
        if self.client:
            return self._parse_with_ai(user_input, session)
        return self._parse_with_keywords(user_input, session)

    def _parse_with_ai(self, user_input: str, session: Optional[CompositionSession] = None) -> Dict[str, Any]:
        """Use AI to parse intent with session context."""
        
        # Build context from session
        session_context = ""
        if session and session.total_bars > 0:
            track_summary = ", ".join([t.name for t in session.tracks])
            session_context = f"""
CURRENT COMPOSITION:
- Genre: {session.genre}
- Key: {session.key} {session.mode}
- Tempo: {session.tempo} BPM
- Duration: {session.total_bars} bars
- Tracks: {track_summary}

Previous messages: {len(session.messages)}
"""

        system_prompt = f"""You are a music assistant. Extract parameters from natural language.
{session_context}
Return ONLY valid JSON:
{{
  "action": "<new|extend|modify|reset>",
  "genre": "<pop|rock|electronic|lofi|jazz|classical|ambient|cinematic|funk|rnb>",
  "mood": "<descriptive word>",
  "tempo": <60-180 or null>,
  "key": "<C|Dm|F#|etc or null>",
  "energy": "<low|medium|high>",
  "duration_bars": <8|16|32>,
  "modify_target": "<all|melody|bass|drums|etc or null>",
  "changes": "<description of changes or null>"
}}

Action rules:
- "new" = fresh composition (default for first message)
- "extend" = add more bars, add tracks ("add strings", "continue", "more bars")
- "modify" = change existing ("make it faster", "change key", "louder drums")
- "reset" = start over ("new song", "start fresh", "forget that")"""

        try:
            response = self.client.chat.completions.create(
                model="llama-3.3-70b-versatile",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_input}
                ],
                temperature=0.3,
                max_tokens=300
            )

            result_text = response.choices[0].message.content.strip()
            if "```" in result_text:
                result_text = result_text.split("```")[1].replace("json", "").strip()
            
            result = json.loads(result_text)
            
            # Plan tracks based on parsed result
            genre = result.get("genre", "pop")
            if result.get("action") in ["new", "extend"]:
                result["track_plan"] = self.track_planner.plan_tracks(user_input, genre)
            
            return result

        except Exception as e:
            print(f"AI parsing failed: {e}")
            return self._parse_with_keywords(user_input, session)

    def _parse_with_keywords(self, user_input: str, session: Optional[CompositionSession] = None) -> Dict[str, Any]:
        """Keyword-based parsing fallback."""
        text = user_input.lower()
        
        result = {
            "action": "new",
            "genre": "pop",
            "mood": "",
            "tempo": None,
            "key": None,
            "energy": "medium",
            "duration_bars": 16,
            "modify_target": None,
            "changes": None
        }

        # Detect action
        if session and session.total_bars > 0:
            if any(w in text for w in ["add", "more", "continue", "extend", "another"]):
                result["action"] = "extend"
            elif any(w in text for w in ["change", "make it", "faster", "slower", "louder", "quieter"]):
                result["action"] = "modify"
            elif any(w in text for w in ["new", "start over", "reset", "fresh", "forget"]):
                result["action"] = "reset"
            else:
                result["action"] = "extend"  # Default to extend if session exists

        # Genre
        for genre in GENRE_CONFIG:
            if genre in text:
                result["genre"] = genre
                break

        # Mood and energy
        mood_energy = {
            "happy": ("happy", "high"), "upbeat": ("happy", "high"),
            "sad": ("sad", "low"), "melancholic": ("melancholic", "low"),
            "calm": ("calm", "low"), "relaxing": ("relaxing", "low"),
            "energetic": ("energetic", "high"), "intense": ("intense", "high"),
            "mysterious": ("mysterious", "medium"), "dark": ("dark", "medium"),
            "epic": ("epic", "high"), "peaceful": ("peaceful", "low"),
        }
        for word, (mood, energy) in mood_energy.items():
            if word in text:
                result["mood"] = mood
                result["energy"] = energy
                break

        # Tempo
        tempo_match = re.search(r'(\d{2,3})\s*bpm', text)
        if tempo_match:
            result["tempo"] = int(tempo_match.group(1))
        elif "faster" in text and session:
            result["tempo"] = min(180, session.tempo + 20)
        elif "slower" in text and session:
            result["tempo"] = max(60, session.tempo - 20)

        # Key
        key_match = re.search(r'\b([A-G][#b]?)\s*(major|minor|m)?\b', user_input, re.IGNORECASE)
        if key_match:
            key = key_match.group(1).upper()
            mode = key_match.group(2)
            if mode and mode.lower() in ["minor", "m"]:
                key += "m"
            result["key"] = key

        # Duration
        dur_match = re.search(r'(\d+)\s*bars?', text)
        if dur_match:
            result["duration_bars"] = min(64, int(dur_match.group(1)))
        elif "short" in text:
            result["duration_bars"] = 8
        elif "long" in text:
            result["duration_bars"] = 32

        # Track planning
        result["track_plan"] = self.track_planner.plan_tracks(user_input, result["genre"])

        return result


# ============== MAIN APPLICATION ==============

class MidiGenApp:
    """Main application with session support."""

    def __init__(self):
        self.parser = IntentParser()
        self.generator = MusicGenerator()
        self.midi_gen = MIDIGenerator()
        self.session: Optional[CompositionSession] = None
        Path("outputs").mkdir(exist_ok=True)

    def _get_session_summary(self) -> str:
        """Get current session state as string."""
        if not self.session or self.session.total_bars == 0:
            return "No active composition"
        
        track_list = "\n".join([f"  - {t.name} ({t.track_type})" for t in self.session.tracks])
        return f"""**Current Composition:**
- Genre: {self.session.genre}
- Key: {self.session.key} {self.session.mode}
- Tempo: {self.session.tempo} BPM
- Duration: {self.session.total_bars} bars
- Tracks ({len(self.session.tracks)}):
{track_list}"""

    def _generate_tracks_from_plan(self, track_plan: List[TrackConfig], root: int, 
                                   mode: str, bars: int, energy: str, genre: str) -> List[Track]:
        """Generate tracks based on plan."""
        tracks = []
        channel_map = {}
        next_channel = 0
        
        for config in track_plan:
            # Assign channels
            if config.track_type == "drums":
                channel = 9
            else:
                if config.track_type not in channel_map:
                    channel_map[config.track_type] = next_channel
                    next_channel = (next_channel + 1) % 9
                    if next_channel == 9:
                        next_channel = 0
                channel = channel_map[config.track_type]
            
            # Get instrument program
            instrument = config.instrument.lower().replace(" ", "_")
            program = GM_INSTRUMENTS.get(instrument, GM_INSTRUMENTS.get("piano", 0))
            
            # Generate notes based on track type
            if config.track_type == "lead":
                notes = self.generator.generate_melody(root, mode, bars, energy, genre)
            elif config.track_type == "counter_melody":
                notes = self.generator.generate_counter_melody(root, mode, bars, energy)
            elif config.track_type == "harmony":
                notes = self.generator.generate_chords(root, genre, bars)
            elif config.track_type == "bass":
                notes = self.generator.generate_bass(root, genre, bars, energy)
            elif config.track_type == "drums":
                notes = self.generator.generate_drums(genre, bars, energy)
            elif config.track_type == "arpeggio":
                notes = self.generator.generate_arpeggio(root, genre, bars, energy)
            elif config.track_type == "pad":
                notes = self.generator.generate_pad(root, mode, bars)
            elif config.track_type == "fx":
                notes = self.generator.generate_fx(root, bars)
            else:
                notes = self.generator.generate_melody(root, mode, bars, energy, genre)
            
            # Update channel for notes
            for note in notes:
                note.channel = channel
            
            track_name = f"{config.instrument.title()} ({config.track_type})"
            tracks.append(Track(track_name, notes, program, channel, config.track_type))
        
        return tracks

    def process_message(self, message: str, history: List[Dict[str, str]]) -> tuple:
        """Process user message with session support."""
        if not message.strip():
            return "", None, history, self._get_session_summary()

        try:
            # Initialize session if needed
            if not self.session:
                self.session = CompositionSession()

            # Parse intent with session context
            intent = self.parser.parse(message, self.session)
            action = intent.get("action", "new")
            
            # Handle reset
            if action == "reset":
                self.session = CompositionSession()
                history.append({"role": "user", "content": message})
                history.append({"role": "assistant", "content": "Started fresh! What would you like to create?"})
                return "", None, history, self._get_session_summary()

            # Get parameters
            genre = intent.get("genre", self.session.genre if action != "new" else "pop")
            config = GENRE_CONFIG.get(genre, GENRE_CONFIG["pop"])
            
            tempo = intent.get("tempo") or (self.session.tempo if action != "new" else random.randint(*config["tempo_range"]))
            key = intent.get("key") or (self.session.key if action != "new" else config["key"])
            mode = config["mode"]
            if "m" in key.lower() and key != key.upper():
                mode = "minor"
                key = key.replace("m", "").replace("M", "")
            
            energy = intent.get("energy", config["energy"])
            bars = intent.get("duration_bars", 16)
            
            root_key = key.replace("m", "").replace("M", "")
            root = NOTE_TO_MIDI.get(root_key, 60)

            # Get track plan
            track_plan = intent.get("track_plan", [])
            if not track_plan:
                track_plan = self.parser.track_planner.plan_tracks(message, genre)

            # Generate new tracks
            new_tracks = self._generate_tracks_from_plan(track_plan, root, mode, bars, energy, genre)

            # Handle action
            if action == "extend" and self.session.total_bars > 0:
                # Merge with existing
                self.session.tracks = self.midi_gen.merge_midi(
                    self.session.tracks, new_tracks, self.session.total_bars, tempo
                )
                self.session.total_bars += bars
            else:
                # New composition
                self.session.tracks = new_tracks
                self.session.total_bars = bars
            
            # Update session state
            self.session.tempo = tempo
            self.session.key = key
            self.session.mode = mode
            self.session.genre = genre

            # Create and save MIDI
            midi = self.midi_gen.create_midi(self.session.tracks, tempo)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"midigen_{genre}_{self.session.session_id}_{timestamp}.mid"
            filepath = Path("outputs") / filename
            midi.save(filepath)

            # Save snapshot
            self.session.generations.append(GenerationSnapshot(
                timestamp=datetime.now(),
                prompt=message,
                tracks=list(self.session.tracks),
                tempo=tempo,
                key=key,
                mode=mode,
                bars=self.session.total_bars
            ))

            # Create response
            response = self._create_response(intent, action, len(new_tracks), filepath)
            
            history.append({"role": "user", "content": message})
            history.append({"role": "assistant", "content": response})
            
            return "", str(filepath), history, self._get_session_summary()

        except Exception as e:
            error_msg = f"Sorry, I encountered an error: {str(e)}"
            history.append({"role": "user", "content": message})
            history.append({"role": "assistant", "content": error_msg})
            return "", None, history, self._get_session_summary()

    def _create_response(self, intent: Dict, action: str, new_tracks: int, filepath: Path) -> str:
        """Create response message."""
        genre = intent.get("genre", "pop")
        mood = intent.get("mood", "")
        
        action_text = {
            "new": "Created",
            "extend": "Extended with",
            "modify": "Modified",
        }.get(action, "Generated")

        track_names = [t.name for t in self.session.tracks[-new_tracks:]] if new_tracks > 0 else []
        
        response = f"""{action_text} {mood + ' ' if mood else ''}{genre} composition!

**This Generation:**
- Added {new_tracks} track(s): {', '.join(track_names) if track_names else 'N/A'}
- Bars added: {intent.get('duration_bars', 16)}

**Total Composition:**
- Duration: {self.session.total_bars} bars
- Total tracks: {len(self.session.tracks)}
- Tempo: {self.session.tempo} BPM
- Key: {self.session.key} {self.session.mode}

Your MIDI file is ready to download!

**Continue building:**
- "Add some strings"
- "Make it more energetic"
- "Add 16 more bars"
- "Change to minor key"
- Or say "new song" to start fresh"""

        return response

    def create_ui(self) -> gr.Blocks:
        """Create Gradio interface."""
        
        with gr.Blocks(title="MidiGen v2.0 - AI Music Creator") as app:
            
            gr.Markdown("""
            # MidiGen v2.0 - AI Music Creator
            
            Create MIDI music through conversation! **Dynamic tracks** (1-8) based on your description.
            **Multi-turn** support - keep building on your composition!
            """)

            with gr.Row():
                with gr.Column(scale=2):
                    chatbot = gr.Chatbot(
                        height=350,
                        label="Chat with MidiGen",
                    )
                    msg = gr.Textbox(
                        placeholder="Describe music (e.g., 'Epic orchestral piece' or 'Simple piano melody')...",
                        label="Your Message",
                        lines=2,
                    )
                    with gr.Row():
                        send_btn = gr.Button("Generate", variant="primary")
                        clear_btn = gr.Button("Clear Chat")
                        reset_btn = gr.Button("New Song", variant="secondary")

                with gr.Column(scale=1):
                    session_display = gr.Markdown(
                        value="**No active composition**\n\nStart by describing the music you want!",
                        label="Session State"
                    )
                    audio_output = gr.File(label="Download MIDI", type="filepath")
                    
                    gr.Markdown("""
                    ### Examples
                    
                    **Simple (1-2 tracks):**
                    - "Solo piano ballad"
                    - "Just acoustic guitar"
                    
                    **Standard (4-5 tracks):**
                    - "Upbeat pop song"
                    - "Chill lo-fi beat"
                    
                    **Rich (6-8 tracks):**
                    - "Epic cinematic orchestra"
                    - "Full electronic production"
                    
                    **Multi-turn:**
                    - "Add strings"
                    - "Make drums louder"
                    - "16 more bars"
                    """)

            def respond(message, history):
                return self.process_message(message, history)

            def reset_session():
                self.session = CompositionSession()
                return [], None, "**No active composition**\n\nStart by describing the music you want!"

            send_btn.click(respond, [msg, chatbot], [msg, audio_output, chatbot, session_display])
            msg.submit(respond, [msg, chatbot], [msg, audio_output, chatbot, session_display])
            clear_btn.click(lambda: ([], None), outputs=[chatbot, audio_output])
            reset_btn.click(reset_session, outputs=[chatbot, audio_output, session_display])

            gr.Examples(
                examples=[
                    "Create a peaceful ambient soundscape",
                    "Epic cinematic orchestra with full arrangement",
                    "Simple solo piano piece",
                    "Funky electronic beat at 125 BPM",
                    "Sad lo-fi hip hop in D minor",
                ],
                inputs=msg,
            )

        return app


def main():
    """Main entry point."""
    print("Starting MidiGen v2.0...")
    print(f"Groq API available: {GROQ_AVAILABLE}")
    
    app = MidiGenApp()
    interface = app.create_ui()
    
    interface.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True,
    )


if __name__ == "__main__":
    main()
